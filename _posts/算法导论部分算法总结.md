# 算法导论部分算法总结

[TOC]

## 前言

由于是考试前夕，所以只总结比较显眼的算法思路，重新回顾一下算法流程，免得明天考试忘记了什么算法。比较重要的章节的思考题大部分都做了一遍，找找考试的手感吧。有时间可以看看实验题，不过基本应该不会太涉及。那就按照复习顺序总结吧。

## 近似算法

### 近似比：

$max(\frac{C}{C^*},\frac{C^*}{C})\leq \rho(n)$

近似解的代价和最优解的代价的比例因子。

### 近似模式：

输入还包含$\epsilon$,该模式是($1+\epsilon$)近似算法。若模式以输入规模n的多项式时间运行，则称为多项式时间近似模式。如果运行时间表达式为$\frac{1}{\epsilon}$多项式，且满足前面性质，称为完全多项式时间近似模式。

比如顶点覆盖问题、集合覆盖问题、旅行商问题都有常数近似解。

## P & NP

P问题为存在多项式时间算法解决的问题

NP问题为给一个实例的解，可以在多项式时间验证此解是否正确

P是NP的子集，但P不一定等于NP

这就衍生出NPC问题：既是NP Hard，也是NP问题

NP-Hard即所有NP问题可以归约成此问题

NP-Hard的证明很复杂，所以一般证明一个问题是否是NPH，需要借助已知的NPC问题，看NPC问题的所有实例是否可以在多项式时间归约成此问题，要是可以，那么就是NPH问题。

常用NPC：3-SAT,哈密顿回路，顶点覆盖，团问题，TSP

2-SAT有多项式解法

![image-20200101182450122](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200101182450122.png)

![image-20200101182609506](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200101182609506.png)

## 字符串匹配

### 朴素字符串匹配

基本思想：以字符串中每一个位置为起始位置，遍历是否符合模式P。执行时间复杂度为O(m(n-m+1))，预处理为0。

### Rabin-Karp算法

这个算法是将字符串转换成数字，比如把字符集看成数集，转成k进制数字，通过取模运算等来判断数值大小是否一样，如果一样再看是否完全一致，如果不一样，直接否决。最坏情况下时间复杂度O(m(n-m+1)),预处理时间为利用honor法则计算模式p的数值，需要$\Theta(m)$。为了解决t和p太大的问题，采用了取模的方法，所以才需要重复检验。期望时间为O(n).

### 有限自动机算法

利用后缀函数构造字符串匹配自动机，模式的每个字符为1个状态，到达最后一个状态则为接受，自动机的转移函数为$\delta(q,a) = \sigma(P_qa)$.需要O(m|$\Sigma$|)的预处理时间和$\Theta(n)$的匹配时间。

### Knuth-Morris-Pratt算法

也是利用了辅助函数来即时有效计算转移函数$\delta$,而$\pi$只有m个元素，所以比有限状态机预处理时间少了常数因子。$Pi$是能构成$Pj$真后缀的最长前缀，则$\pi[j] = i$,$s' = s+(q-\pi[q])$,时间复杂度预处理$O(m)$,匹配时间$\Theta(n)$。可用摊还分析中聚合分析得出时间复杂度，循环中q增加n次，只有while循环中q会减小，所以最多减小n次，所以while循环执行$\Theta(n)$.

## 多项式与快速傅里叶变换

首先一个多项式可以用系数来表示，比如$A = a_nx^n+a_{n-1}x^{n-1}+\dots+a_0$,此多项式次数界为$n+1$。然后此多项式计算可以使用honor法则在$\Theta(n)$内运算结束。但是两个多项式的乘法如果直接运算时间复杂度比较高，需要$O(n^2)$,这就引发了多项式的另一种表示方法:点值表示。

点值表示和以前学的多元方程组解很像，将$a_i$当成变量，给n个点值对，解n个方程组，得出$a_i$。这个解法如果直接计算也很麻烦，需要矩阵求逆，O($n^3$)。若取拉格朗日插值法，只需O($n^2$),但时间复杂度还是很高。

这时候提出了快速傅里叶变换，通过取2n个单位复数根作为点值的取值，也达到$Theta(nlg(n))$转换到点值对，并且从点值对$Theta(nlg(n))$转换到系数，点值表示的多项式乘法很简单，所以总的多项式乘法能达到$Theta(nlg(n))$。

利用单位复数根性质，使用FFT，计算DFT(a)。

使用分治策略，$A(x) = A^{[0]}(x^2)+xA^{[1]}(x^2)$,分别计算A0和A1，根据折半引理($(w_n^{k+n/2})^2 = (w_n^{k})^2$),计算规模也变为一半，所以可以用分治策略，有一点需要注意:

![image-20200101191914508](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200101191914508.png)

我们要是计算可以直接手算，没必要走流程。

插值更复杂，使用逆DFT。

考试应该只会涉及思想和手动计算，写算法只能大致写一下了。

## 基本图算法

图的表示:邻接矩阵和邻接表

广度优先搜索：BFS 找到了最短路径(权重为1)，时间复杂度为$O(V+E)$

DFS：$\Theta(V+E)$,记录了开始时间和完成时间，便于后面操作，前驱子图构成了不相交森林

括号化定理

拓扑排序，结点完成时间的逆序，但是可能有不同的拓扑排序，注意定义:对于任意一条边(u,v),拓扑排序中，u在v之前。

强连通分量：按照拓扑排序的顺序进行DFS，前驱子图中不同深度优先搜索树就是一个强连通分量。

## MST

大致算法：贪心，最小生成树有V-1条边，每次添加一个安全边。

### kruskal算法

利用并查集，每次合并两个集合，安全边即为不在同一个集合中两个点的最短边

```python
edges=[]
for  edge as u,v in sorted(G.E):
    if find-set(u) != find-set(v):
        edges.append(edge)
        union(u,v)
return edges
```

时间复杂度为$O(ElgV)$。

### Prim算法

使用BFS，一直保持一颗树，类似dijkstra。

安全边为$S$与$V-S$之间轻量边。

```python
for v in V: 
    v.minAdjEdge = MAX
    v.pre = None
root.minAdjEdge = 0
que = priority-queue (G.V)  # sort by minAdjEdge
while not que.isempty():
    u = que.extractMin()
    for v in Adj(u):
        if v in que and v.minAdjEdge>w(u,v):
            v.pre = u
            v.minAdjEdge = w(u,v)
```

建立优先队列，$O(V)$；执行V次extractmin,$O(Vlg(V))$;decreaseKey需要lg(V),循环E次，$O(Elg(V))$.共$O(ElgV)$

如果使用Fibonacci-Heap，decrease-key为O(1),所以O(E+Vlg(V))。

## 单源最短路径

主要是Bellman-ford和Dijkstra算法。如果是有向无环图，可以利用拓扑排序，按序relax边。

研究这个问题主要不是会使用算法，而是了解最短路径的性质从而解决更多的问题。

### 最短路径的子路径也是最短路径

### 三角不等式:$\delta(s,v)\leq\delta(s,u)+w(u,v)$

### 负权环不能使用这些方法处理，但bellmanford可以检测出

### 负权重边Dijkstra不能解决

### 松弛操作 路径松弛性质可以用来证明是最短路径

### 有向无环图的单源最短路径

$\Theta(V+E)$

利用拓扑排序，relax E次，拓扑排序，$\Theta(V+E)$

### Bellman-Ford

$O(VE)$,一般对此算法进行改进适应不同的问题，比如双调最短路径问题

```python
def bellman-ford(G,s):
    initialize(G,s)
    for ct in range(|V|-1): # v-1 times
        for u,v as edge in E:
            relax(u,v,w(u,v))
    for u,v as edge in E:
        if v.distance > u.distance + w(u,v):
            return False
    return True
```

### Dijkstra算法

```python
def dijkstra(G,s):
    initialize(G,s)
    paths=[]
    q = priority-queue(G.V) # sort by distance
    while not q.empty():
        u = q.extract-min()
        paths.append(u)
        for v in Adj(u):
            relax(u,v,w(u,v))
```

时间复杂度还是主要花在堆上，使用二叉堆为$O(Elg(V))$，使用F-Heap为$O(VlgV+E)$.

## 所有结点对的最短路径

### 矩阵乘法

使用动态规划，子问题为长度为k的最短路径，则动态规划的状态转移方程为$l_{ij}^{m} = min_{1\leq k\leq n}(l_{ik}^{m-1}+w_{kj})$

由于m大于等于V-1时，得到最终的最短路径，m=1时，矩阵为W，所以可以自底向上计算每一步，时间复杂度为$O(V^4)$,而我们可以类比分治法解矩阵乘法，$W^4 = (W^2)^2$,所以可以把复杂度降到$O(V^3lgV)$

### Floyd-Warshall算法

此算法也是使用动态规划，但是子问题和矩阵乘法不同，其子问题为中间结点为集合{1,2,…,k}的最短路径，前驱矩阵$\Pi$记录前驱结点。

<img src="C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200101202435734.png" alt="image-20200101202435734" style="zoom:67%;" />

### Johnson算法

通过对边权重新赋值，使得边权大于等于0，再使用V次Dijkstra算法，得到所有点对之间最短路径。

首先构造新图，添加新结点s，此结点到其他结点的距离都为0，再使用Bellman-Ford算法算出s到其他结点的最短路径距离记为函数h(v),求新的非负值权$w'(u,v) = w(u,v)+h(u)-h(v)$,这种操作的正确性应该时从三角不等式启发而来，$w'(u,v)$一定大于等于0，且最短路径和原图不变，要想求得权值，需要在最后加上h(v)-h(u)

## 最大流

### Ford-Fulkerson方法

在关联的残存网络中寻找一条增广路径，然后对这些边加增广路径中最小容量，或减去最小容量，减少流量的操作这也叫抵消操作cancellation

```python
def ford-fulkerson(G,s,t):
    for edge in G.E: edge.f = 0
    while exists path p:s->t  in Gf:
        cf(p) = min{cf(u,v):(u,v) is in p}
        for edge in p:
            if edge  in E:
                edge.f +=cf(p)
            else: reverse_edge.f -=cf(p)
```

关键是会画图

![image-20200101211106157](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200101211106157.png)

左边是G，右边是残存网络$G_f$

## 摊还分析

### 9.1. 聚合分析(aggregate analysis)

 一个 n 个操作的序列最坏情况下花费的总时间为![](https://latex.codecogs.com/gif.latex?T(n)), 则在最坏情况下, 每个操作的摊还代价为 ![](https://latex.codecogs.com/gif.latex?\frac{T(n)}{n})

如栈中的 push, pop 操作都是 ![](https://latex.codecogs.com/gif.latex?O(1)), 增加一个新操作 `multipop`, 

```python
def multipop(stk,k):
  while not stk.empty() and k>0:
    stk.pop()
    k-=1
```

multipop 的时间复杂度为 min(stk.size,k), 最坏情况为 ![](https://latex.codecogs.com/gif.latex?O(n)), 则 n 个包含 push pop multipop 的操作列的最坏情况是 ![](https://latex.codecogs.com/gif.latex?O(n^2)), 并不是这样, 注意到, 必须栈中有元素, 再 pop, 所以 push 操作与pop 操作(包含 multipop中的pop), 个数相当, 所以 实际上应为 ![](https://latex.codecogs.com/gif.latex?O(n)), 每个操作的摊还代价 为![](https://latex.codecogs.com/gif.latex?O(1))

<a id="markdown-92-核算法-accounting-method" name="92-核算法-accounting-method"></a>

### 9.2. 核算法 (accounting method)

对不同操作赋予不同费用 cost (称为摊还代价 ![](https://latex.codecogs.com/gif.latex?c_i')), 可能多于或者少于其实际代价 ![](https://latex.codecogs.com/gif.latex?c_i) 

当 ![](https://latex.codecogs.com/gif.latex?c_i'>c_i), 将  ![](https://latex.codecogs.com/gif.latex?c_i'-c_i)( `credit`) 存入数据结构中的特定对象.. 对于后续 ![](https://latex.codecogs.com/gif.latex?c_i'<c_i)时, 可以使用这些credit来 支付差额.. 有要求 
![](https://latex.codecogs.com/gif.latex?\sum_{i}c_i'&space;\geqslant&space;\sum_{i}c_i)

如栈

|    op    | ![](https://latex.codecogs.com/gif.latex?c_i') | ![](https://latex.codecogs.com/gif.latex?c_i) |
| :------: | :--------------------------------------------: | :-------------------------------------------: |
|   push   |                       2                        |                       1                       |
|   pop    |                       0                        |                       1                       |
| multipop |                       0                        |                   min(s,k)                    |

由核算法, 摊还代价满足要求,  所以 n 个操作总代价 ![](https://latex.codecogs.com/gif.latex?O(n)), 每个操作摊还代价为 ![](https://latex.codecogs.com/gif.latex?O(1))

<a id="markdown-93-势能法potential-method" name="93-势能法potential-method"></a>

### 9.3. 势能法(potential method)

势能释放用来支付未来操作的代价, 势能是整个数据结构的, 不是特定对象的(核算法是).

数据结构 ![](https://latex.codecogs.com/gif.latex?D_0)为初始状态, 依次 执行 n 个操作 ![](https://latex.codecogs.com/gif.latex?op_i)进行势能转换 ![](https://latex.codecogs.com/gif.latex?D_i&space;=op_i(D_{i-1}),&space;i=1,2,\ldots,n) , 各操作代价为 ![](https://latex.codecogs.com/gif.latex?c_i)

势函数 ![](https://latex.codecogs.com/gif.latex?\Phi:D_i\rightarrow&space;R), ![](https://latex.codecogs.com/gif.latex?\Phi(D_i))即为 ![](https://latex.codecogs.com/gif.latex?D_i)的势

则第 i 个操作的摊还代价 
![](https://latex.codecogs.com/gif.latex?c_i'=c_i+\Phi(D_i)-\Phi(D_{i-1}))

则
![](https://latex.codecogs.com/gif.latex?\sum_{i=1}^{n}c_i'=\sum_{i=1}^{n}c_i+\Phi(D_n)-\Phi(D_0))

如果定义一个势函数![](https://latex.codecogs.com/gif.latex?\Phi,&space;st&space;\&space;\Phi(D_i)\geqslant\Phi(D_0)), 则总摊还代价给出了实际代价的一个上界
可以简单地以 ![](https://latex.codecogs.com/gif.latex?D_0&space;\text{Reference-state},&space;then&space;\&space;\Phi(D_0)=0)

例如栈操作, 
设空栈为 ![](https://latex.codecogs.com/gif.latex?D_0), 势函数定义为栈的元素数
对于push, ![](https://latex.codecogs.com/gif.latex?\Phi(D_i)-\Phi(D_{i-1})=1)
则 ![](https://latex.codecogs.com/gif.latex?c'&space;=&space;c&space;+\Phi(D_i)-\Phi(D_{i-1})&space;=&space;c+1&space;=&space;2)

对于 multipop,  ![](https://latex.codecogs.com/gif.latex?\Phi(D_i)-\Phi(D_{i-1})=-&space;min(k,s))
则 ![](https://latex.codecogs.com/gif.latex?c'&space;=&space;c&space;-&space;min(k,s)&space;=&space;0)

同理 pop  的摊还代价也是0, 则总摊还代价的上界(最坏情况) 为 ![](https://latex.codecogs.com/gif.latex?O(n))

## 动态规划

最优子结构：问题的最优解有相关子问题的最优解组合而成，而且这些子问题可以独立求解。

动态规划有两种实现方法:

- 带备忘的自顶向下法，但是由于是递归，所以常数因子比较大
- 自底向上法

子问题图：逆拓扑排序和DFS

重构解

设计方法：

- 刻画最优解的结构特征
- 递归定义最优解的值（状态转移方程）
- 计算最优解的值
- 重构最优解

使用剪切粘贴法证明具有最优子结构

重叠子问题：递归算法反复求解相同的子问题。

### LCS

 ![在这里插入图片描述](https://img-blog.csdn.net/20181011100055534?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzM0MDAxOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 

最优子结构和重叠子问题性质都比较直观

而且LCS问题可以用来解决很多其他类似问题，比如找最长回文串，可以逆向后和原串求LCS。

### 最优二叉搜索树

最优子结构：一颗最优二叉树的子树必然是最优二叉树，而且可以对根节点进行遍历，构造原问题最优解。

 ![在这里插入图片描述](https://img-blog.csdn.net/20181011201759330?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzM0MDAxOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 

 ![在这里插入图片描述](https://img-blog.csdn.net/20181011202133308?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzM0MDAxOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 

## 贪心算法

最优子结构证明：剪切-粘贴

证明贪心选择是最优解的一部分，替换法证明，假设一个最优解，证明替换后仍然是最优解









